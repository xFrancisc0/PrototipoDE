{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST UNITARIOS de los qx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se realizan importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time\n",
    "\n",
    "from q2_memory import q2_memory\n",
    "from q2_time import q2_time\n",
    "\n",
    "from q3_memory import q3_memory\n",
    "from q3_time import q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaracion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLRequestRawDataZip = \"https://drive.usercontent.google.com/download?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis&export=download&authuser=0&confirm=t&uuid=d3ab3e9e-0e9e-4dfe-945a-a73286456315&at=APZUnTUiCQBVxpETIVQcpNAPpA7U%3A1720637781554\"\n",
    "\n",
    "NombreMuestra = \"qx_test_muestra.json\"\n",
    "NombreArchivo = \"qx_test.json\"\n",
    "\n",
    "dataset_path_parcial = f'TemporalBlobs/{NombreArchivo}'\n",
    "muestra_path_parcial = f'TemporalBlobs/{NombreMuestra}'\n",
    "n_elementos = 500\n",
    "\n",
    "dataset_path = Path(dataset_path_parcial)\n",
    "muestra_path = Path(muestra_path_parcial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se procede a realizar las pruebas unitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_muestras_aleatorias_de_dataset(dataset_path, n_elementos, muestra_path):\n",
    "    df = pd.read_json(dataset_path)\n",
    "    muestra = df.sample(n=n_elementos, random_state=1)\n",
    "    muestra.to_json(muestra_path, orient='records', lines=False)\n",
    "\n",
    "def ExisteDatasetTestsBooleano():\n",
    "    if dataset_path.exists():\n",
    "        print(\"Ya existe el dataset, no se creará\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No existe el dataset de pruebas, se creará\")\n",
    "        return False\n",
    "\n",
    "def ExisteMuestraBooleano():\n",
    "    if muestra_path.exists():\n",
    "        print(\"Ya existe la muestra, no se creará\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No existe la muestra, se creará\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el dataset, no se creará\n",
      "Ya existe la muestra, no se creará\n",
      "\n",
      "Q1: Las top 10 fechas donde hay más tweets y sus usuarios: \n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13    105.6 MiB    105.6 MiB           1   @profile\n",
      "    14                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    15    108.5 MiB      0.0 MiB           2       with open(Path(file_path), 'r') as f:\n",
      "    16    108.5 MiB      3.0 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    17                                         \n",
      "    18    109.2 MiB      0.7 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    19                                             \n",
      "    20                                             # Extraer la columna 'username' de 'user' en una nueva columna\n",
      "    21    109.4 MiB      0.2 MiB        1001       df['username'] = df['user'].apply(lambda x: x['username'] if isinstance(x, dict) and 'username' in x else None)\n",
      "    22                                             # Seleccionar las columnas deseadas y ordenar por 'retweetCount' en orden descendente\n",
      "    23    109.8 MiB      0.4 MiB           1       result = df[['date', 'username', 'retweetCount']].sort_values(by='retweetCount', ascending=False).drop(columns=['retweetCount']).head(10)\n",
      "    24                                         \n",
      "    25    109.8 MiB      0.0 MiB           1       return result\n",
      "\n",
      "\n",
      "              date         username\n",
      "499  1613808704000    fawadchaudhry\n",
      "431  1613914786000           aajtak\n",
      "491  1613108960000     noconversion\n",
      "348  1613554896000  NewsroomPostCom\n",
      "244  1613098619000       Raza_AKhan\n",
      "63   1613355902000    iMani_KaurRai\n",
      "186  1613612041000  KKSinghAzadSoch\n",
      "270  1613709080000       sran_subeg\n",
      "136  1613356436000      HeerSaleti_\n",
      "292  1613526876000     Magnum__girl\n",
      "\n",
      "Los top 10 emojis más usados con su respectivo conteo: \n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    45    109.8 MiB    109.8 MiB           1   @profile\n",
      "    46                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "    47    110.2 MiB      0.0 MiB           2       with open(file_path, 'r') as f:\n",
      "    48    110.2 MiB      0.4 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    49                                             \n",
      "    50    110.5 MiB      0.2 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    51                                             \n",
      "    52    110.5 MiB      0.0 MiB           1       all_emojis = []\n",
      "    53                                             \n",
      "    54                                             # Aplicar la función a cada fila del DataFrame\n",
      "    55    110.7 MiB      0.0 MiB         501       for _, fila in df.iterrows():\n",
      "    56    110.7 MiB      0.2 MiB         500           all_emojis.extend(extraer_emojis_de_columnas(fila))\n",
      "    57                                             \n",
      "    58                                             # Contar emojis y obtener los 10 más comunes\n",
      "    59    110.7 MiB      0.0 MiB           1       emoji_counts = Counter(all_emojis)\n",
      "    60    110.7 MiB      0.0 MiB           1       top_10_emojis = emoji_counts.most_common(10)\n",
      "    61                                             \n",
      "    62    110.7 MiB      0.0 MiB           1       return top_10_emojis\n",
      "\n",
      "\n",
      "[('🌾', 45), ('🙏', 38), ('🇮🇳', 29), ('❤️', 24), ('👉', 24), ('🚜', 22), ('ꜱ', 19), ('🖤', 18), ('💚', 16), ('🙏🏻', 16)]\n",
      "\n",
      "Q3: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos:\n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7    110.7 MiB    110.7 MiB           1   @profile\n",
      "     8                                         def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     9    110.7 MiB      0.0 MiB           2       with open(file_path, 'r') as f:\n",
      "    10    110.7 MiB      0.0 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    11                                             \n",
      "    12    110.7 MiB      0.0 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    13                                             \n",
      "    14    110.7 MiB      0.0 MiB        1371       df['mentionedUsers'] = df['mentionedUsers'].apply(lambda x: [user['username'] for user in x] if x else []) #El campo sera una lista de usuarios\n",
      "    15    110.7 MiB      0.0 MiB           1       df['mentionedUsersCount'] = df['mentionedUsers'].apply(len) #Se cuentan los usuarios mencionados de cada lista y se crea el campo mentioned users\n",
      "    16    110.8 MiB      0.1 MiB           1       top_10_users = df.nlargest(10, 'mentionedUsersCount') #limit 10\n",
      "    17    110.8 MiB      0.0 MiB          11       result = [(row['user']['username'], row['mentionedUsersCount']) for _, row in top_10_users.iterrows()]\n",
      "    18                                         \n",
      "    19    110.8 MiB      0.0 MiB           1       return result\n",
      "\n",
      "\n",
      "[('DaljitNakhwal', 18), ('loyal90901246', 13), ('loyal90901246', 12), ('Navdeep83453953', 12), ('TujinderAujla', 11), ('pawanrai1313', 9), ('kisan_panipat', 8), ('ramitsaxena', 8), ('biroke_singh', 7), ('Hifzu__', 7)]\n"
     ]
    }
   ],
   "source": [
    "if(not ExisteDatasetTestsBooleano()):\n",
    "    RawDataInput = Utility.ObtenerDataPorHTTPRequest(URLRequestRawDataZip, 'GET', 'JSON', True)\n",
    "    archivo_path = Path(f'TemporalBlobs/{NombreArchivo}')\n",
    "    \n",
    "    with archivo_path.open('wb') as f:\n",
    "        f.write(RawDataInput.encode(\"utf8\"))  # Escribir los datos en el archivo\n",
    "\n",
    "if(not ExisteMuestraBooleano()):\n",
    "    print(f\"Generando muestra aleatoria de {n_elementos} elementos: \")\n",
    "    muestra_path = obtener_muestras_aleatorias_de_dataset(dataset_path, n_elementos, muestra_path)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Q1: Las top 10 fechas donde hay más tweets y sus usuarios: \")\n",
    "print(\"===========================================================\")\n",
    "q1_m = q1_memory(muestra_path_parcial)\n",
    "#q1_t = q1_time(muestra_path)\n",
    "print(q1_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Los top 10 emojis más usados con su respectivo conteo: \")\n",
    "print(\"===========================================================\")\n",
    "q2_m = q2_memory(muestra_path_parcial)\n",
    "#q2_t = q2_time(muestra_path)\n",
    "print(q2_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Q3: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos:\")\n",
    "print(\"===========================================================\")\n",
    "q3_m = q3_memory(muestra_path_parcial)\n",
    "#q3_t = q3_time(muestra_path)\n",
    "print(q3_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
