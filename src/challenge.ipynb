{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se realizan importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Servicios.GoogleDriveService.GoogleDriveService import GoogleDriveService\n",
    "from Servicios.AdvanaService.AdvanaService import AdvanaService\n",
    "from Servicios.OrquestadorService.OrchestrateService import OrchestrateService\n",
    "\n",
    "from Utilidades.GlobalUtility import ObtenerDataPorHTTPRequest\n",
    "import Utilidades.GlobalUtility as Utility\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time\n",
    "\n",
    "from q2_memory import q2_memory\n",
    "from q2_time import q2_time\n",
    "\n",
    "from q3_memory import q3_memory\n",
    "from q3_time import q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se definen variables de Buckets de GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdContenedorBronze = \"1yQCQ3BhNPdXiz890KTF9iNB5qdeTATlV\" #Bronce\n",
    "IdContenedorGold = \"1TMq41pVhsEDK1IUP4kQHzf7aIsagVihE\" #Gold\n",
    "\n",
    "URLRequestRawDataZip = \"https://drive.usercontent.google.com/download?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis&export=download&authuser=0&confirm=t&uuid=d3ab3e9e-0e9e-4dfe-945a-a73286456315&at=APZUnTUiCQBVxpETIVQcpNAPpA7U%3A1720637781554\"\n",
    "NombreArchivo = \"data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se definen variables de Advana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONObjEntregaAdvana = {\"name\": \"TDD (Pruebas) EnviarPeticionHTTP() Advana Fmateu\",\n",
    "           \"mail\": \"francisco.mateu.araneda@gmail.com Aun en desarrollo\",\n",
    "           \"github_url\": \"https://github.com/xFrancisc0/PrototipoDE\"}\n",
    "           \n",
    "URLRequestEntregaAdvana = \"https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Se instancian los servicios de la aplicación y se inyectan en el orquestador\n",
    "El objetivo es una vez que se instancie el orquestador, que se orqueste una ingesta de data desde https://drive.google.com/file/d/1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis/view?usp=sharing y que se guarde en la zona bronze del \"Datalake\" de prototipo Es una URL pública: https://drive.google.com/drive/u/2/folders/1nVbnD0pgYnAeym3lUoNna5cE7goN2U5N (Fue desplegado este Datalake para ser visto desde el exterior sin permisos de edición. Esto es para mostrar el funcionamiento del presente proyecto)\n",
    "\n",
    "Posteriormente, el orquestador cargara la data desde la zona bronce, se le aplicarán todos los procedimientos y se guardará en la zona Gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear instancias de servicios e inyectarlos en el orquestador para mayor simplicidad\n",
    "google_drive_service = GoogleDriveService()\n",
    "advana_service = AdvanaService()\n",
    "\n",
    "# Crear instancia de OrchestrateService, inyectando GoogleDriveService\n",
    "orchestrate_service = OrchestrateService(google_drive_service, advana_service)\n",
    "\n",
    "#Destruir objetos que no se ocuparan\n",
    "del google_drive_service\n",
    "del advana_service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se obtiene la raw data y se almacena en zona bronze\n",
    "Para ver el datalake: https://drive.google.com/drive/u/2/folders/1nVbnD0pgYnAeym3lUoNna5cE7goN2U5N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo JSON POR HTTP Request\n",
      "Archivo JSON descomprimido y cargado exitosamente.\n",
      "Subiendo data a Google Drive\n",
      "Archivo data.json ya existente en google cloud con ID 1IanrwIKgeEuboadR8tIFT4VsFHWyxFAL eliminado (overwrite).\n",
      "Archivo 'data.json' subido correctamente. ID: 1MdFYAAsdPDxbE2PJe834CTMLIsUoGN_0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RawDataInput = Utility.ObtenerDataPorHTTPRequest(URLRequestRawDataZip, 'GET', 'JSON', True)\n",
    "\n",
    "#Cargar raw data a zona bronze\n",
    "orchestrate_service.google_drive_service.subir_archivo_a_contenedor(IdContenedorBronze, NombreArchivo, RawDataInput)\n",
    "\n",
    "#Destruir objeto RawDataInput\n",
    "del RawDataInput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se obtiene la data de la zona de bronze y se guarda en TemporalBlobs. Se elimina de la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos encontrados:  [{'kind': 'drive#file', 'mimeType': 'application/json', 'id': '1MdFYAAsdPDxbE2PJe834CTMLIsUoGN_0', 'name': 'data.json'}]\n",
      "Descargando 25%.\n",
      "Descargando 51%.\n",
      "Descargando 77%.\n",
      "Descargando 100%.\n",
      "Archivo bronze guardado en: TemporalBlobs\\data.json\n"
     ]
    }
   ],
   "source": [
    "#Cargar en memoria de zona bronze\n",
    "BronzeMetadata = orchestrate_service.google_drive_service.listar_archivos_en_contenedorSTR(IdContenedorBronze)\n",
    "BronzeDataInput = orchestrate_service.google_drive_service.descargar_archivo_porid(BronzeMetadata[0][\"id\"])\n",
    "\n",
    "# Crear una instancia de Path para la ruta del archivo\n",
    "archivo_path = Path(f'TemporalBlobs/{NombreArchivo}')\n",
    "\n",
    "# Asegurarse de que el directorio existe\n",
    "archivo_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Escribir los datos al archivo\n",
    "with open(archivo_path, 'wb') as f:\n",
    "    f.write(BronzeDataInput)  # Escribir los datos en formato de bytes\n",
    "\n",
    "print(f\"Archivo bronze guardado en: {archivo_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se procede a realizar las transformaciones requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1: Las top 10 fechas donde hay más tweets y sus usuarios: \n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13    541.7 MiB    541.7 MiB           1   @profile\n",
      "    14                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    15   1227.5 MiB      0.0 MiB           2       with open(Path(file_path), 'r') as f:\n",
      "    16   1227.5 MiB    685.9 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    17                                         \n",
      "    18   1246.5 MiB     19.0 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    19                                             \n",
      "    20                                             # Extraer la columna 'username' de 'user' en una nueva columna\n",
      "    21   1248.5 MiB  -3985.5 MiB      234815       df['username'] = df['user'].apply(lambda x: x['username'] if isinstance(x, dict) and 'username' in x else None)\n",
      "    22                                             # Seleccionar las columnas deseadas y ordenar por 'retweetCount' en orden descendente\n",
      "    23   1255.2 MiB      6.7 MiB           1       result = df[['date', 'username', 'retweetCount']].sort_values(by='retweetCount', ascending=False).drop(columns=['retweetCount']).head(10)\n",
      "    24                                         \n",
      "    25   1255.2 MiB      0.0 MiB           1       return result\n",
      "\n",
      "\n",
      "                             date         username\n",
      "111329  2021-02-12T10:10:56+00:00  RakeshTikaitBKU\n",
      "7645    2021-02-23T09:40:21+00:00     dhruv_rathee\n",
      "89780   2021-02-14T09:22:23+00:00        rupikaur_\n",
      "88911   2021-02-14T11:07:50+00:00        amaanbali\n",
      "111556  2021-02-12T09:44:31+00:00      jedijasmin_\n",
      "64492   2021-02-16T21:33:51+00:00        rupikaur_\n",
      "108072  2021-02-12T16:11:35+00:00      RaviSinghKA\n",
      "60721   2021-02-17T04:38:50+00:00     sherryontopp\n",
      "29510   2021-02-20T11:38:08+00:00     sherryontopp\n",
      "24160   2021-02-21T06:33:27+00:00     sherryontopp\n",
      "\n",
      "Los top 10 emojis más usados con su respectivo conteo: \n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    45   1167.3 MiB   1167.3 MiB           1   @profile\n",
      "    46                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "    47   1247.3 MiB      0.0 MiB           2       with open(file_path, 'r') as f:\n",
      "    48   1247.3 MiB     79.9 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    49                                             \n",
      "    50   1265.7 MiB     18.5 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    51                                             \n",
      "    52   1265.7 MiB      0.0 MiB           1       all_emojis = []\n",
      "    53                                             \n",
      "    54                                             # Aplicar la función a cada fila del DataFrame\n",
      "    55   1314.6 MiB     35.5 MiB      117408       for _, fila in df.iterrows():\n",
      "    56   1314.6 MiB      3.6 MiB      117407           all_emojis.extend(extraer_emojis_de_columnas(fila))\n",
      "    57                                             \n",
      "    58                                             # Contar emojis y obtener los 10 más comunes\n",
      "    59   1314.6 MiB      0.1 MiB           1       emoji_counts = Counter(all_emojis)\n",
      "    60   1314.6 MiB      0.0 MiB           1       top_10_emojis = emoji_counts.most_common(10)\n",
      "    61                                             \n",
      "    62   1314.6 MiB      0.0 MiB           1       return top_10_emojis\n",
      "\n",
      "\n",
      "[('🙏', 10858), ('🇮🇳', 7453), ('🌾', 7352), ('❤️', 5411), ('👉', 4841), ('🚜', 2747), ('☬', 2726), ('💚', 2447), ('❤', 2373), ('🙏🏻', 2313)]\n",
      "\n",
      "Q3: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos:\n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7   1181.7 MiB   1181.7 MiB           1   @profile\n",
      "     8                                         def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     9   1247.2 MiB      0.0 MiB           2       with open(file_path, 'r') as f:\n",
      "    10   1247.2 MiB     65.4 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    11                                             \n",
      "    12   1265.1 MiB     17.9 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    13                                             \n",
      "    14   1275.6 MiB     10.5 MiB      338218       df['mentionedUsers'] = df['mentionedUsers'].apply(lambda x: [user['username'] for user in x] if x else []) #El campo sera una lista de usuarios\n",
      "    15   1278.3 MiB      2.7 MiB           1       df['mentionedUsersCount'] = df['mentionedUsers'].apply(len) #Se cuentan los usuarios mencionados de cada lista y se crea el campo mentioned users\n",
      "    16   1278.5 MiB      0.2 MiB           1       top_10_users = df.nlargest(10, 'mentionedUsersCount') #limit 10\n",
      "    17   1278.5 MiB      0.0 MiB          11       result = [(row['user']['username'], row['mentionedUsersCount']) for _, row in top_10_users.iterrows()]\n",
      "    18                                         \n",
      "    19   1278.5 MiB      0.0 MiB           1       return result\n",
      "\n",
      "\n",
      "[('SunilMe24609328', 50), ('smacsingle75', 50), ('smacsingle75', 50), ('GAGANDE94683905', 50), ('Krishna91228901', 50), ('SunilMe24609328', 50), ('smacsingle75', 50), ('smacsingle75', 50), ('AjitsinhJagirda', 50), ('smacsingle75', 50)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Q1: Las top 10 fechas donde hay más tweets y sus usuarios: \")\n",
    "print(\"===========================================================\")\n",
    "q1_m = q1_memory(archivo_path)\n",
    "#q1_t = q1_time(muestra_path)\n",
    "print(q1_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Los top 10 emojis más usados con su respectivo conteo: \")\n",
    "print(\"===========================================================\")\n",
    "q2_m = q2_memory(archivo_path)\n",
    "#q2_t = q2_time(muestra_path)\n",
    "print(q2_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Q3: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos:\")\n",
    "print(\"===========================================================\")\n",
    "q3_m = q3_memory(archivo_path)\n",
    "#q3_t = q3_time(muestra_path)\n",
    "print(q3_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El dataset posterior a sus transformaciones se guarda en la zona gold del Datalake\n",
    "Para ver el datalake: https://drive.google.com/drive/u/2/folders/1nVbnD0pgYnAeym3lUoNna5cE7goN2U5N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BronzeDataETL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m orchestrate_service\u001b[38;5;241m.\u001b[39mgoogle_drive_service\u001b[38;5;241m.\u001b[39msubir_archivo_a_contenedor(IdContenedorGold, NombreArchivo, \u001b[43mBronzeDataETL\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Destruir objeto RawDataInput\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m BronzeDataETL\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BronzeDataETL' is not defined"
     ]
    }
   ],
   "source": [
    "orchestrate_service.google_drive_service.subir_archivo_a_contenedor(IdContenedorGold, NombreArchivo, BronzeDataETL)\n",
    "\n",
    "#Destruir objeto RawDataInput\n",
    "del BronzeDataETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
