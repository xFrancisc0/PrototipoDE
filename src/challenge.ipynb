{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se realizan importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Servicios.GoogleDriveService.GoogleDriveService import GoogleDriveService\n",
    "from Servicios.AdvanaService.AdvanaService import AdvanaService\n",
    "from Servicios.OrquestadorService.OrchestrateService import OrchestrateService\n",
    "\n",
    "from Utilidades.GlobalUtility import ObtenerDataPorHTTPRequest\n",
    "import Utilidades.GlobalUtility as Utility\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time\n",
    "\n",
    "from q2_memory import q2_memory\n",
    "from q2_time import q2_time\n",
    "\n",
    "from q3_memory import q3_memory\n",
    "from q3_time import q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se definen variables de Buckets de GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdContenedorBronze = \"1yQCQ3BhNPdXiz890KTF9iNB5qdeTATlV\" #Bronce\n",
    "IdContenedorGold = \"1TMq41pVhsEDK1IUP4kQHzf7aIsagVihE\" #Gold\n",
    "\n",
    "URLRequestRawDataZip = \"https://drive.usercontent.google.com/download?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis&export=download&authuser=0&confirm=t&uuid=d3ab3e9e-0e9e-4dfe-945a-a73286456315&at=APZUnTUiCQBVxpETIVQcpNAPpA7U%3A1720637781554\"\n",
    "NombreArchivo = \"data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se definen variables de Advana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONObjEntregaAdvana = {\"name\": \"TDD (Pruebas) EnviarPeticionHTTP() Advana Fmateu\",\n",
    "           \"mail\": \"francisco.mateu.araneda@gmail.com Aun en desarrollo\",\n",
    "           \"github_url\": \"https://github.com/xFrancisc0/PrototipoDE\"}\n",
    "           \n",
    "URLRequestEntregaAdvana = \"https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Se instancian los servicios de la aplicaciÃ³n y se inyectan en el orquestador\n",
    "El objetivo es una vez que se instancie el orquestador, que se orqueste una ingesta de data desde https://drive.google.com/file/d/1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis/view?usp=sharing y que se guarde en la zona bronze del \"Datalake\" de prototipo Es una URL pÃºblica: https://drive.google.com/drive/u/2/folders/1nVbnD0pgYnAeym3lUoNna5cE7goN2U5N (Fue desplegado este Datalake para ser visto desde el exterior sin permisos de ediciÃ³n. Esto es para mostrar el funcionamiento del presente proyecto)\n",
    "\n",
    "Posteriormente, el orquestador cargara la data desde la zona bronce, se le aplicarÃ¡n todos los procedimientos y se guardarÃ¡ en la zona Gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear instancias de servicios e inyectarlos en el orquestador para mayor simplicidad\n",
    "google_drive_service = GoogleDriveService()\n",
    "advana_service = AdvanaService()\n",
    "\n",
    "# Crear instancia de OrchestrateService, inyectando GoogleDriveService\n",
    "orchestrate_service = OrchestrateService(google_drive_service, advana_service)\n",
    "\n",
    "#Destruir objetos que no se ocuparan\n",
    "del google_drive_service\n",
    "del advana_service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se obtiene la raw data y se almacena en zona bronze\n",
    "Para ver el datalake: https://drive.google.com/drive/u/2/folders/1nVbnD0pgYnAeym3lUoNna5cE7goN2U5N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo JSON POR HTTP Request\n",
      "Archivo JSON descomprimido y cargado exitosamente.\n",
      "Subiendo data a Google Drive\n",
      "Archivo data.json ya existente en google cloud con ID 1IanrwIKgeEuboadR8tIFT4VsFHWyxFAL eliminado (overwrite).\n",
      "Archivo 'data.json' subido correctamente. ID: 1MdFYAAsdPDxbE2PJe834CTMLIsUoGN_0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RawDataInput = Utility.ObtenerDataPorHTTPRequest(URLRequestRawDataZip, 'GET', 'JSON', True)\n",
    "\n",
    "#Cargar raw data a zona bronze\n",
    "orchestrate_service.google_drive_service.subir_archivo_a_contenedor(IdContenedorBronze, NombreArchivo, RawDataInput)\n",
    "\n",
    "#Destruir objeto RawDataInput\n",
    "del RawDataInput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se obtiene la data de la zona de bronze y se guarda en TemporalBlobs. Se elimina de la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos encontrados:  [{'kind': 'drive#file', 'mimeType': 'application/json', 'id': '1MdFYAAsdPDxbE2PJe834CTMLIsUoGN_0', 'name': 'data.json'}]\n",
      "Descargando 25%.\n",
      "Descargando 51%.\n",
      "Descargando 77%.\n",
      "Descargando 100%.\n",
      "Archivo bronze guardado en: TemporalBlobs\\data.json\n"
     ]
    }
   ],
   "source": [
    "#Cargar en memoria de zona bronze\n",
    "BronzeMetadata = orchestrate_service.google_drive_service.listar_archivos_en_contenedorSTR(IdContenedorBronze)\n",
    "BronzeDataInput = orchestrate_service.google_drive_service.descargar_archivo_porid(BronzeMetadata[0][\"id\"])\n",
    "\n",
    "# Crear una instancia de Path para la ruta del archivo\n",
    "archivo_path = Path(f'TemporalBlobs/{NombreArchivo}')\n",
    "\n",
    "# Asegurarse de que el directorio existe\n",
    "archivo_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Escribir los datos al archivo\n",
    "with open(archivo_path, 'wb') as f:\n",
    "    f.write(BronzeDataInput)  # Escribir los datos en formato de bytes\n",
    "\n",
    "print(f\"Archivo bronze guardado en: {archivo_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se procede a realizar las transformaciones requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1: Las top 10 fechas donde hay mÃ¡s tweets y sus usuarios: \n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13    541.7 MiB    541.7 MiB           1   @profile\n",
      "    14                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    15   1227.5 MiB      0.0 MiB           2       with open(Path(file_path), 'r') as f:\n",
      "    16   1227.5 MiB    685.9 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    17                                         \n",
      "    18   1246.5 MiB     19.0 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    19                                             \n",
      "    20                                             # Extraer la columna 'username' de 'user' en una nueva columna\n",
      "    21   1248.5 MiB  -3985.5 MiB      234815       df['username'] = df['user'].apply(lambda x: x['username'] if isinstance(x, dict) and 'username' in x else None)\n",
      "    22                                             # Seleccionar las columnas deseadas y ordenar por 'retweetCount' en orden descendente\n",
      "    23   1255.2 MiB      6.7 MiB           1       result = df[['date', 'username', 'retweetCount']].sort_values(by='retweetCount', ascending=False).drop(columns=['retweetCount']).head(10)\n",
      "    24                                         \n",
      "    25   1255.2 MiB      0.0 MiB           1       return result\n",
      "\n",
      "\n",
      "                             date         username\n",
      "111329  2021-02-12T10:10:56+00:00  RakeshTikaitBKU\n",
      "7645    2021-02-23T09:40:21+00:00     dhruv_rathee\n",
      "89780   2021-02-14T09:22:23+00:00        rupikaur_\n",
      "88911   2021-02-14T11:07:50+00:00        amaanbali\n",
      "111556  2021-02-12T09:44:31+00:00      jedijasmin_\n",
      "64492   2021-02-16T21:33:51+00:00        rupikaur_\n",
      "108072  2021-02-12T16:11:35+00:00      RaviSinghKA\n",
      "60721   2021-02-17T04:38:50+00:00     sherryontopp\n",
      "29510   2021-02-20T11:38:08+00:00     sherryontopp\n",
      "24160   2021-02-21T06:33:27+00:00     sherryontopp\n",
      "\n",
      "Los top 10 emojis mÃ¡s usados con su respectivo conteo: \n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    45   1167.3 MiB   1167.3 MiB           1   @profile\n",
      "    46                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "    47   1247.3 MiB      0.0 MiB           2       with open(file_path, 'r') as f:\n",
      "    48   1247.3 MiB     79.9 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    49                                             \n",
      "    50   1265.7 MiB     18.5 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    51                                             \n",
      "    52   1265.7 MiB      0.0 MiB           1       all_emojis = []\n",
      "    53                                             \n",
      "    54                                             # Aplicar la funciÃ³n a cada fila del DataFrame\n",
      "    55   1314.6 MiB     35.5 MiB      117408       for _, fila in df.iterrows():\n",
      "    56   1314.6 MiB      3.6 MiB      117407           all_emojis.extend(extraer_emojis_de_columnas(fila))\n",
      "    57                                             \n",
      "    58                                             # Contar emojis y obtener los 10 mÃ¡s comunes\n",
      "    59   1314.6 MiB      0.1 MiB           1       emoji_counts = Counter(all_emojis)\n",
      "    60   1314.6 MiB      0.0 MiB           1       top_10_emojis = emoji_counts.most_common(10)\n",
      "    61                                             \n",
      "    62   1314.6 MiB      0.0 MiB           1       return top_10_emojis\n",
      "\n",
      "\n",
      "[('ðŸ™', 10858), ('ðŸ‡®ðŸ‡³', 7453), ('ðŸŒ¾', 7352), ('â¤ï¸', 5411), ('ðŸ‘‰', 4841), ('ðŸšœ', 2747), ('â˜¬', 2726), ('ðŸ’š', 2447), ('â¤', 2373), ('ðŸ™ðŸ»', 2313)]\n",
      "\n",
      "Q3: El top 10 histÃ³rico de usuarios (username) mÃ¡s influyentes en funciÃ³n del conteo de las menciones (@) que registra cada uno de ellos:\n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7   1181.7 MiB   1181.7 MiB           1   @profile\n",
      "     8                                         def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     9   1247.2 MiB      0.0 MiB           2       with open(file_path, 'r') as f:\n",
      "    10   1247.2 MiB     65.4 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    11                                             \n",
      "    12   1265.1 MiB     17.9 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    13                                             \n",
      "    14   1275.6 MiB     10.5 MiB      338218       df['mentionedUsers'] = df['mentionedUsers'].apply(lambda x: [user['username'] for user in x] if x else []) #El campo sera una lista de usuarios\n",
      "    15   1278.3 MiB      2.7 MiB           1       df['mentionedUsersCount'] = df['mentionedUsers'].apply(len) #Se cuentan los usuarios mencionados de cada lista y se crea el campo mentioned users\n",
      "    16   1278.5 MiB      0.2 MiB           1       top_10_users = df.nlargest(10, 'mentionedUsersCount') #limit 10\n",
      "    17   1278.5 MiB      0.0 MiB          11       result = [(row['user']['username'], row['mentionedUsersCount']) for _, row in top_10_users.iterrows()]\n",
      "    18                                         \n",
      "    19   1278.5 MiB      0.0 MiB           1       return result\n",
      "\n",
      "\n",
      "[('SunilMe24609328', 50), ('smacsingle75', 50), ('smacsingle75', 50), ('GAGANDE94683905', 50), ('Krishna91228901', 50), ('SunilMe24609328', 50), ('smacsingle75', 50), ('smacsingle75', 50), ('AjitsinhJagirda', 50), ('smacsingle75', 50)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Q1: Las top 10 fechas donde hay mÃ¡s tweets y sus usuarios: \")\n",
    "print(\"===========================================================\")\n",
    "q1_m = q1_memory(archivo_path)\n",
    "#q1_t = q1_time(muestra_path)\n",
    "print(q1_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Los top 10 emojis mÃ¡s usados con su respectivo conteo: \")\n",
    "print(\"===========================================================\")\n",
    "q2_m = q2_memory(archivo_path)\n",
    "#q2_t = q2_time(muestra_path)\n",
    "print(q2_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Q3: El top 10 histÃ³rico de usuarios (username) mÃ¡s influyentes en funciÃ³n del conteo de las menciones (@) que registra cada uno de ellos:\")\n",
    "print(\"===========================================================\")\n",
    "q3_m = q3_memory(archivo_path)\n",
    "#q3_t = q3_time(muestra_path)\n",
    "print(q3_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El dataset posterior a sus transformaciones se guarda en la zona gold del Datalake\n",
    "Para ver el datalake: https://drive.google.com/drive/u/2/folders/1nVbnD0pgYnAeym3lUoNna5cE7goN2U5N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BronzeDataETL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m orchestrate_service\u001b[38;5;241m.\u001b[39mgoogle_drive_service\u001b[38;5;241m.\u001b[39msubir_archivo_a_contenedor(IdContenedorGold, NombreArchivo, \u001b[43mBronzeDataETL\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Destruir objeto RawDataInput\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m BronzeDataETL\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BronzeDataETL' is not defined"
     ]
    }
   ],
   "source": [
    "orchestrate_service.google_drive_service.subir_archivo_a_contenedor(IdContenedorGold, NombreArchivo, BronzeDataETL)\n",
    "\n",
    "#Destruir objeto RawDataInput\n",
    "del BronzeDataETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
