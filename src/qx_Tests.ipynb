{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST UNITARIOS de los qx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se realizan importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time\n",
    "\n",
    "from q2_memory import q2_memory\n",
    "from q2_time import q2_time\n",
    "\n",
    "from q3_memory import q3_memory\n",
    "from q3_time import q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaracion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLRequestRawDataZip = \"https://drive.usercontent.google.com/download?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis&export=download&authuser=0&confirm=t&uuid=d3ab3e9e-0e9e-4dfe-945a-a73286456315&at=APZUnTUiCQBVxpETIVQcpNAPpA7U%3A1720637781554\"\n",
    "\n",
    "NombreMuestra = \"qx_test_muestra.json\"\n",
    "NombreArchivo = \"qx_test.json\"\n",
    "\n",
    "dataset_path_parcial = f'TemporalBlobs/{NombreArchivo}'\n",
    "muestra_path_parcial = f'TemporalBlobs/{NombreMuestra}'\n",
    "n_elementos = 500\n",
    "\n",
    "dataset_path = Path(dataset_path_parcial)\n",
    "muestra_path = Path(muestra_path_parcial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se procede a realizar las pruebas unitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_muestras_aleatorias_de_dataset(dataset_path, n_elementos, muestra_path):\n",
    "    df = pd.read_json(dataset_path)\n",
    "    muestra = df.sample(n=n_elementos, random_state=1)\n",
    "    muestra.to_json(muestra_path, orient='records', lines=False)\n",
    "\n",
    "def ExisteDatasetTestsBooleano():\n",
    "    if dataset_path.exists():\n",
    "        print(\"Ya existe el dataset, no se creará\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No existe el dataset de pruebas, se creará\")\n",
    "        return False\n",
    "\n",
    "def ExisteMuestraBooleano():\n",
    "    if muestra_path.exists():\n",
    "        print(\"Ya existe la muestra, no se creará\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No existe la muestra, se creará\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el dataset, no se creará\n",
      "Ya existe la muestra, no se creará\n",
      "\n",
      "Los top 10 emojis más usados con su respectivo conteo: \n",
      "===========================================================\n",
      "Filename: D:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    45    105.7 MiB    105.7 MiB           1   @profile\n",
      "    46                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "    47    108.6 MiB      0.0 MiB           2       with open(file_path, 'r') as f:\n",
      "    48    108.6 MiB      2.9 MiB           1           data = json.load(f)  # Cargar el archivo JSON\n",
      "    49                                             \n",
      "    50    109.3 MiB      0.7 MiB           1       df = pd.DataFrame(data)  # Crear un DataFrame a partir de los datos JSON\n",
      "    51                                             \n",
      "    52    109.3 MiB      0.0 MiB           1       all_emojis = []\n",
      "    53                                             \n",
      "    54                                             # Aplicar la función a cada fila del DataFrame\n",
      "    55    109.7 MiB      0.1 MiB         501       for _, fila in df.iterrows():\n",
      "    56    109.7 MiB      0.3 MiB         500           all_emojis.extend(extraer_emojis_de_columnas(fila))\n",
      "    57                                             \n",
      "    58                                             # Contar emojis y obtener los 10 más comunes\n",
      "    59    109.7 MiB      0.0 MiB           1       emoji_counts = Counter(all_emojis)\n",
      "    60    109.7 MiB      0.0 MiB           1       top_10_emojis = emoji_counts.most_common(10)\n",
      "    61                                             \n",
      "    62    109.7 MiB      0.0 MiB           1       return top_10_emojis\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'psql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===========================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m q2_m \u001b[38;5;241m=\u001b[39m q2_memory(muestra_path_parcial)\n\u001b[1;32m---> 25\u001b[0m q2_t \u001b[38;5;241m=\u001b[39m \u001b[43mq2_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmuestra_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(q2_m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03mprint(\"\")\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03mprint(\"Q3: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos:\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mprint(q3_m)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Francisco\\Desarrollos\\PrototipoPythonLATAM\\src\\q2_time.py:21\u001b[0m, in \u001b[0;36mq2_time\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)  \u001b[38;5;66;03m# Crear un DataFrame a partir de los datos JSON\u001b[39;00m\n\u001b[0;32m     11\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124mSELECT emoji, COUNT(*) as emoji_count\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124mFROM (\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124mLIMIT 10\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpsql\u001b[49m\u001b[38;5;241m.\u001b[39msqldf(query, \u001b[38;5;28mlocals\u001b[39m())\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'psql' is not defined"
     ]
    }
   ],
   "source": [
    "if(not ExisteDatasetTestsBooleano()):\n",
    "    RawDataInput = Utility.ObtenerDataPorHTTPRequest(URLRequestRawDataZip, 'GET', 'JSON', True)\n",
    "    archivo_path = Path(f'TemporalBlobs/{NombreArchivo}')\n",
    "    \n",
    "    with archivo_path.open('wb') as f:\n",
    "        f.write(RawDataInput.encode(\"utf8\"))  # Escribir los datos en el archivo\n",
    "\n",
    "if(not ExisteMuestraBooleano()):\n",
    "    print(f\"Generando muestra aleatoria de {n_elementos} elementos: \")\n",
    "    muestra_path = obtener_muestras_aleatorias_de_dataset(dataset_path, n_elementos, muestra_path)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Q1: Las top 10 fechas donde hay más tweets y sus usuarios: \")\n",
    "print(\"===========================================================\")\n",
    "q1_m = q1_memory(muestra_path_parcial)\n",
    "#q1_t = q1_time(muestra_path)\n",
    "print(q1_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Los top 10 emojis más usados con su respectivo conteo: \")\n",
    "print(\"===========================================================\")\n",
    "q2_m = q2_memory(muestra_path_parcial)\n",
    "#q2_t = q2_time(muestra_path)\n",
    "print(q2_m)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Q3: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos:\")\n",
    "print(\"===========================================================\")\n",
    "q3_m = q3_memory(muestra_path_parcial)\n",
    "#q3_t = q3_time(muestra_path)\n",
    "print(q3_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
